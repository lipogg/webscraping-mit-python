{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sessions und Cookies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Um zu verstehen, was Sessions und Cookies eigentlich sind, müssen wir nochmal zum HTTP-Protokoll zurückkehren. HTTP ist nämlich \"zustandslos\", es übermittelt keine Informationen über vergangene Seitenaufrufe. Das heißt, dass ein Webserver nicht anhand einer simplen HTTP-Anfrage erkennen kann, ob derselbe Client bereits zuvor eine Anfrage gestellt hat. Etwas formeller ausgedrückt:\n",
    "\n",
    "> HTTP is stateless: there is no link between two requests being successively carried out on the same connection. This immediately has the prospect of being problematic for users attempting to interact with certain pages coherently, for example, using e-commerce shopping baskets. But while the core of HTTP itself is stateless, HTTP cookies allow the use of stateful sessions. Using header extensibility, HTTP Cookies are added to the workflow, allowing session creation on each HTTP request to share the same context, or the same state.\n",
    "\n",
    "Quelle: [MDN Contributors (2023)](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview#http_is_stateless_but_not_sessionless)\n",
    "\n",
    "Damit der Webserver denselben Client wiedererkennen kann, ist also eine zusätzliche Information notwendig: ein sogenannter Cookie, den der Server dem Client beim ersten Seitenaufruf übermittelt, und den der Client beim wiederholten Seitenaufruf im Header einer HTTP-Anfrage dem Server wieder zusendet. So kann der Client dem Webserver bei einer HTTP-Anfrage zusätzliche Informationen übermitteln. Formell ausgedrückt:\n",
    "\n",
    "> An HTTP cookie (web cookie, browser cookie) is a small piece of data that a server sends to a user's web browser. The browser may store the cookie and send it back to the same server with later requests. Typically, an HTTP cookie is used to tell if two requests come from the same browser—keeping a user logged in, for example. It remembers stateful information for the stateless HTTP protocol.\n",
    "\n",
    "Quelle: [MDN Contributors (2023)](https://developer.mozilla.org/en-US/docs/Web/HTTP/Cookies)\n",
    "\n",
    "Beim Aufruf einer Webseite werden meist mehrere Cookies als Schlüssel-Wert-Paare übermittelt. Darunter befindet sich insbesondere bei Loginvorgängen häufig ein Cookie, der eine ID für die aktuelle Session, also für eine Benutzersitzung, enthält. Anhand des Session-ID Cookies erkennt der Webserver, dass derselbe Client bereits zuvor die Webseite aufgerufen hat, und die in anderen Cookies gespeicherten Informationen können so beim wiederholten Seitenaufruf wiederverwendet werden. Je nach der Art der Dienste, für die auf einer Webseite Cookies verwendet werden, haben Sessions eine unterschiedliche Gültigkeitsdauer: Beim Login in ein Onlinebanking-Account sind das oft nur wenige Minuten, während Sessions beim Login in ein soziales Netzwerk sogar wochenlang aufrechterhalten werden können. Wenn die Gültigkeit einer Session erlischt, dann wird die Session-ID gelöscht und ein:e Nutzer:in wird beim nächsten Seitenaufruf zum erneuten Login aufgefordert.\n",
    "\n",
    "Softwareentwickler Valentin Despa hat einen meiner Meinung nach ganz passenden Vergleich zum Verständnis von Cookies vorgeschlagen. Das Prinzip von Session-ID-Cookies ist laut Despa vergleichbar mit einer Garderobe: Bei der Abgabe eines Kleidungsstücks bekommt man einen Abholschein mit einer einzigartigen Nummer, anhand derer die Person an der Garderobe später das abgegebene Kleidungsstück wieder der richtigen Person zuordnen kann. Wenn die Person das Kleidungsstück erhalten hat, hat der Abholschein keine Bedeutung mehr und wird in den Müll geworfen.\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"cookies_sessionid.png\" alt=\"Cookies Vergleich\" class=\"bg-transparent\" width=\"100%\">\n",
    "\n",
    "Wie funktionieren Cookies? Das Garderoben-Prinzip. Quelle: [Valentin Despa (2022)](https://www.youtube.com/watch?v=V0pzXU6FbQA)\n",
    ":::\n",
    "\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"cookies_sessions.png\" alt=\"Cookies Vergleich\" class=\"bg-transparent\" width=\"100%\">\n",
    "\n",
    "Wie funktionieren Cookies? Die Session-ID. Quelle: [Valentin Despa (2021)](https://www.youtube.com/watch?v=GhrvZ5nUWNg)\n",
    ":::\n",
    "\n",
    "Cookies können ebenfalls über die Browser-Entwicklertools eingesehen werden. Nachdem beim Aufruf des Onlineshops conrad.com die Option \"Decline Cookies\" im Pop-Up-Cookiebanner ausgewählt wurde, sind in den Entwicklertools nur noch die funktionalen Cookies sichtbar, darunter auch ein Cookie mit dem Namen \"session-id-cookie\" und einer Session-ID als Wert.\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"conrad_session_cookie.png\" alt=\"Conrad Beispiel\" class=\"bg-transparent\" width=\"75%\">\n",
    "\n",
    "Session-ID-Cookie in den Entwicklertools beim Aufruf der Seite conrad.com\n",
    ":::\n",
    "\n",
    "Das Beispiel zeigt auch noch einmal, dass Cookiebanner häufig missverständlich formuliert sind: Mit \"Cookies ablehnen\" sind meist nicht die funktionalen Cookies gemeint, also Cookies, welche für die Funktionalität der Webseite erforderlich sind, sondern nur solche, die zum Verfolgen des Nutzerverhaltens (Tracking) und zu Werbezwecken dienen.\n",
    "\n",
    "```{note}\n",
    "Cookies können auch über die Browser-Entwicklertools gelöscht werden: und zwar mit Ctrl bzw. Cmd + Shift + P und Suche nach \"Clear site data\".\n",
    "```\n",
    "\n",
    "Soweit zum Verständnis von Cookies und Sessions. Aber wie können wir denn beim Web Scraping mit Sessions, Cookies und Cookiebannern umgehen?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cookie und Session Handling mit Selenium: Beispiel Login\n",
    "\n",
    "In Selenium haben wir ganz automatisch Sessions verwendet: Jedes Mal, wenn mit webdriver.Chrome() ein neues Webdriver-Objekt initialisiert wird, wird auch eine neue Session, also eine Nutzersitzung gestartet. Im Folgenden schauen wir uns einen Anwendungsfall an, bei dem beim Web Scraping mit Selenium Cookies verwendet werden: ein Login-Vorgang.\n",
    "\n",
    "Angenommen, wir wollen eine Seite in mehreren Sessions scrapen. Dann müssten wir uns jedes Mal neu einloggen und jedes Mal das Inputfeld mit find_element() suchen, die Inputdaten mit send_keys() eingeben und anschließend die Eingabe mit click() bestätigen. Das können wir vereinfachen, indem wir beim ersten Login die Login-Cookies speichern und bei der nächsten Anfrage direkt die Cookies mitsenden. Wir schauen uns wieder das [Code-Beispiel von jemand anderem](https://www.youtube.com/watch?v=xbjMnuLIilw) an (allerdings mit einer kleinen Anpassung):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Session starten und Seite abrufen\n",
    "\n",
    "from selenium import webdriver\n",
    "import json\n",
    "\n",
    "url = \"https://twitter.com\"\n",
    "cookies_file = \"twitter_cookies.json\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(url)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An diesem Punkt öffnet sich das Loginfenster und wir können entweder unsere Logindaten manuell eingeben oder mithilfe von Selenium. Zur Einfachheit halber nehmen wir an, dass wir die Logindaten manuell eingeben."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Cookies speichern\n",
    "\n",
    "cookies = driver.get_cookies()\n",
    "cookies_file = \"cookies.json\"\n",
    "\n",
    "with open(cookies_file, \"w\") as f:\n",
    "    json.dump(cookies, f, indent=4)\n",
    "\n",
    "driver.quit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Da Cookies bei der HTTP-Anfrage als Schlüssel-Wert-Paare übergeben werden, bietet es sich an, die Daten im JSON-Format zu speichern. Es gibt aber auch andere Möglichkeiten, zum Beispiel das Python-spezifische Dateiformat pickle, welches nur zum Zwischenspeichern von Python-Objekten konzipiert wurde. Die Datei mit den Login-Cookies kann dann in der nächsten Session eingelesen und die Cookies an den Server gesendet werden:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Neue Session starten und Login-Cookies übergeben\n",
    "\n",
    "with open(cookies_file, 'r') as f:\n",
    "    cookies = json.load(f)\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "for cookie in cookies:\n",
    "    driver.add_cookie(cookie)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cookie und Session Handling mit requests: Beispiel Login\n",
    "\n",
    "Bei der Verwendung von requests sind wir bisher nicht mit Sessions und Cookies in Berührung gekommen. Aber auch requests bietet die Möglichkeit, eine Session zu initialisieren und bei einer Anfrage Cookies zu übermitteln.\n",
    "\n",
    "Ein Session-Objekt kann mit requests wie folgt erstellt werden:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "session = requests.Session()\n",
    "session.get(\"https//example.com\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Eine Session muss am Ende auch immer wieder geschlossen werden:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "session.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Da man das schnell vergessen kann, kann zum Erstellen von Sessions dieselbe Syntax verwendet werden, die ihr bereits vom Lesen und Schreiben von Dateien kennt:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with requests.Session() as session:\n",
    "    session.get(\"https//example.com\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Die Session wird dann automatisch geschlossen. Da beim Web Scraping mit requests anders als beim Scrapen mit Selenium nicht automatisch eine Session erstellt wird, muss vor einem Login-Vorgang eine Session initialisiert werden. Nur so können nach der erfolgreichen Anemldung über die Loginseite die Anmeldedaten beim Aufruf der zu scrapenden Seite an den Server übermittelt werden. Das wird am folgenden Beispiel deutlich. Ein Login-Vorgang auf der Seite realpython.com sieht mit requests zum Beispiel so aus:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# So solltet ihr die Logindaten in der Praxis aber NICHT angeben, s.u.\n",
    "username = \"beispiel@email.com\"\n",
    "password = \"beispielpasswort\"\n",
    "\n",
    "with requests.Session() as session:\n",
    "    login_url = \"https://realpython.com/account/login/\"\n",
    "\n",
    "    session.get(login_url)\n",
    "    csrf_token = session.cookies['csrftoken']\n",
    "\n",
    "    params = {\"login\": username, \"password\": password, \"csrfmiddlewaretoken\": csrf_token}\n",
    "\n",
    "    session.headers.update({'User-Agent': 'Mozilla/5.0', 'Referer': 'https://realpython.com'})\n",
    "    response = session.post(login_url, params)\n",
    "    response.status_code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Der Login-Vorgang wird hier mithilfe einer HTTP-POST-Anfrage vorgenommen. Im Abschnitt \"Statisch vs. Dynamisch?\" haben wir diese Art der Anfrage bereits am Beispiel der Suche auf projekt-gutenberg.de kennengelernt. Die Logindaten werden dabei als Argument params der post-Methode übergeben. Die post-Methode wird (und das ist wichtig!) aus der aktuellen Nutzersitzung, also der Session, heraus gestellt: Es heißt im Beispiel session.post() und nicht requests.post()!\n",
    "\n",
    "Zu beachten ist auch, dass in dem Beispiel oben neben den Logindaten noch ein CSRF-Token für den Loginvorgang benötigt wird. CSRF steht für Cross-Site Request Forgery und beschreibt eine bestimmte Art eines Angriffs, der verhindert werden soll, indem der Server bei jeder Anfrage überprüft, ob der Client einen CSRF-Token mitsendet, der dem Token entspricht, den der Server dem Client beim Login übermittelt hat. Es wird damit also einfach gesagt überprüft, ob ein Link, auf den ein:e angemeldete:r Nutzer:in zugreifen will, schädlich ist und dem Client womöglich durch einen Dritten (\"Hacker\") untergejubelt wurde: In diesem Fall würde bei der Anfrage nämlich kein gültiges Token übermittelt werden. Eine ausführlichere Erläuterung findet ihr [hier](https://dr-dsgvo.de/csrf-cookies-zur-gefahrenabwehr-bedeutung-und-problem-mit-dem-datenschutz/).\n",
    "\n",
    "Wie genau das CSRF-Token und die Loginparameter bei der Anfrage heißen müssen, kann nach der manuellen Anmeldung auf der Seite wieder dem Network-Tab in den Browser-Entwicklertools entnommen werden. Dazu müssen einfach die Anfrageparameter zur Anfrage für die Seite https://realpython.com/account/login/ unter \"Payload\" und \"Cookies\" betrachtet werden.\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"realpython_anfrage.png\" alt=\"Realpython Beispiel\" class=\"bg-transparent\" width=\"75%\">\n",
    "\n",
    "Ausschnitt aus dem Header der HTTP-POST-Anfrage beim Login auf realpython.com\n",
    ":::\n",
    "\n",
    "Nachdem der Login-Vorgang erfolgt ist, kann regulär eine HTTP-GET-Anfrage für die gesuchten Inhalte durchgeführt werden, in diesem Fall für eine Seite mit Notifications, die nur eingeloggte Nutzer:innen sehen können:\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"realpython_notifications.png\" alt=\"Realpython Beispiel\" class=\"bg-transparent\" width=\"75%\">\n",
    "\n",
    "Ermitteln der gesuchten Elemente auf der Notifications-Seite\n",
    ":::\n",
    "\n",
    "Wichtig ist dabei allerdings, dass die Anfrage wieder aus der aktuellen Nutzersitzung heraus gestellt wird, also wieder mit session.get() anstelle von requests.get():"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "scrape_url = \"https://realpython.com/account/notifications/\"\n",
    "page = session.get(scrape_url)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "soup.select(\".card-title.mb-3\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Der Beispiel-Loginvorgang auf realpython.com ist auf viele Anwendungsfälle übertragbar. Verschiedene Webseiten nutzen aber verschiedene Authentifizierungsverfahren und ein Blick in die Entwicklertools ist beim Schreiben des Codes unerlässlich. Und nicht immer muss zum Login eine HTTP-POST-Methode angewandt werden. Für den Login auf Webseiten, welche Authentifizierungsverfahren wie beispielsweise OAuth verwenden, ist die Anmeldung in requests vorimplementiert. Dazu mehr hier: https://requests.readthedocs.io/en/latest/user/authentication/.\n",
    "\n",
    "```{note}\n",
    "Aber Achtung: Im Beispiel wurden die **Logindaten** einfach in den Code selbst geschrieben. Das solltet ihr in der Praxis nicht machen, vor allem dann nicht, wenn ihr euer Skript später mit anderen teilen wollt. Stattdessen solltet ihr die Logindaten aus einer Datei o.Ä. einlesen. Eine simple Möglichkeit ist, die Zugangsdaten in einer JSON-Datei zu speichern und diese anschließend einzulesen mit der bereits bekannten Funktion json.load() aus dem Paket json. auf die Logindaten kann dann wie auf ein ganz normales Dictionary zugegriffen werden nach dem Schema creds_dict[\"password\"].\n",
    "```\n",
    "\n",
    "\n",
    "```{note}\n",
    "Beachtet auch, dass sich die **rechtliche Bewertung** zur grundsätzlichen Zulässigkeit vom Scrapen auch entgegen der Nutzungsbedingungen einer Webseite, von der wir im Kapitel 6.1 \"Der rechtliche Rahmen\" ausgegangen sind, ändert, sobald Daten hinter einem Login gescraped werden. Ob dies im Einzelfall zulässig ist, solltet ihr prüfen, bevor ihr die Daten extrahiert.\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cookie Consent: Selenium\n",
    "\n",
    "Wenn die Seite google.com mithilfe von Selenium und dem Chrome Webdriver aufgerufen wird, dann öffnet sich ein Cookiebanner, also ein Pop-Up-Fenster, das Nutzer:innen auffordert, der Verwendung von Cookies durch die Seite zuzustimmen:\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"google_cookiebanner.png\" alt=\"Google Beispiel\" class=\"bg-transparent\" width=\"75%\">\n",
    "\n",
    "Google Cookie-Consent-Seite beim Seitenaufruf mit Selenium und dem Chrome Webdriver\n",
    ":::\n",
    "\n",
    "Um mithilfe von Selenium die optionalen Cookies abzulehnen, muss einfach nur der \"Reject All\"-Button geklickt werden, und dazu suchen wir den Button und simulieren den Mausklick mit der bereits bekannten Methode click():\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"google_cookiebutton.png\" alt=\"Google Beispiel\" class=\"bg-transparent\" width=\"75%\">\n",
    "\n",
    "Id des \"Reject All\"-Buttons ermitteln\n",
    ":::"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.google.com/\")\n",
    "driver.find_element(By.ID, \"W0wltc\").click()\n",
    "driver.quit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Voilà! Der Cookiebanner ist verschwunden."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cookie Consent: Requests\n",
    "\n",
    "Zur Anzeigen von Cookiebannern wird JavaScript verwendet. Das heißt, dass bei einer Anfrage mit requests die Seite ohne den Cookiebanner angezeigt wird: das Pop-Up-Fenster öffnet sich gar nicht erst. Heißt das aber, dass beim Web Scrapen mit requests und BeautifulSoup Cookiebanner gar nicht relevant sind? Nicht ganz, denn es kommt auch vor, dass beim erstmaligen Aufruf einer Seite eine Weiterleitung auf eine Cookie-Consent-Seite erfolgt. Anders ausgedrückt: eine Anfrage mit requests, die keine Cookies im Anfrage-Header mit übergibt, wird auf eine Seite umgeleitet, welche die Einwilligung in die Verwendung von Cookies abfragt. Erst, wenn ein:e Nutzer:in der Verwendung von Cookies zugestimmt hat, wird beim erneuten Seitenaufruf die ursprünglich angefragte Seite angezeigt. Das ist beispielsweise der Fall beim Aufruf von google.com mit deaktiviertem JavaScript. Mit deaktiviertem JavaScript wird anstatt der Anzeige des Cookiebanner-Pop-Up-Fensters die Anfrage auf eine separate Cookie-Consent-Seite weitergeleitet:\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"google_cookieconsent.png\" alt=\"Google Beispiel\" class=\"bg-transparent\" width=\"75%\">\n",
    "\n",
    "Google Cookie-Consent-Seite beim Seitenaufruf mit deaktiviertem JavaScript\n",
    ":::\n",
    "\n",
    "Entsprechend wird beim Versuch, Suchergebnisse mit requests und BeautifulSoup zu scrapen, die Cookie-Consent-Seite zurückgegeben und nicht die Seite mit den Suchergebnissen:\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.google.com/search?q=python\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "# soup.body"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In den Browser-Entwicklertools unter Network -> Cookies können die Cookies, die beim Seitenaufruf im Header der HTTP-Anfrage an den Webserver geschickt werden, eingesehen werden:\n",
    "\n",
    ":::{figure-md}\n",
    "<img src=\"google_cookieconsent.png\" alt=\"Google Beispiel\" class=\"bg-transparent\" width=\"75%\">\n",
    "\n",
    "Cookies beim Seitenaufruf mit deaktiviertem JavaScript\n",
    ":::\n",
    "\n",
    "Beim erstmaligen Aufruf der Seite wird ein Cookie mit dem Namen \"CONSENT\" und dem Wert \"PENDING+612\" (die Zahl kann jedoch variieren) mitgesandt. Diesen Cookie können wir bei der Anfrage mit Requests im Anfrage-Header mit angeben. Dabei müssen wir den Wert des CONSENT-Cookies allerdings auf \"YES+\" setzen. Die Anfrage gibt dann die angefragte Seite zurück und nicht die Cookie-Consent-Seite:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with requests.Session() as session:\n",
    "\n",
    "    url = \"https://www.google.com/search?q=python\"\n",
    "    consent_cookie = {'CONSENT': 'YES+',}\n",
    "    response = session.get(url, cookies=consent_cookie)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    # soup.body\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wie genau der Consent-Cookie heißt und welcher Wert eingesetzt werden muss, variiert, aber das Prinzip ist auch auf andere Webseiten übertragbar. Um herauszufinden, wie der Cookie heißt, helfen euch wie in diesem Beispiel die Entwicklertools weiter."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Quellen\n",
    "\n",
    "```{bibliography}\n",
    "   :list: enumerated\n",
    "   :filter: keywords % \"cookies\"\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
